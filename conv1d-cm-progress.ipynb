{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deactivating callbacks can be especially useful when you do a parameter search (say with sklearn GridSearchCV). If, for instance, you use a callback for learning rate scheduling (e.g. via LRScheduler) and want to test its usefulness, you can compare the performance once with and once without the callback.\n",
    "\n",
    "implement gridSearch\n",
    "\n",
    "implement space_cnn\n",
    "\n",
    "implement long core for cnn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Signal and Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mods = ['BPSK', 'DQPSK', 'GFSK', 'GMSK', 'OQPSK',\n",
    "        'PAM4', 'PAM8', 'PSK8', 'QAM16', 'QAM64', 'QPSK']\n",
    "class_num = len(mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat(\n",
    "    \"D:/batch100000_symbols128_sps8_baud1_snr5.dat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_from_mat(data, size):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for mod in mods:\n",
    "        real = np.array(data[mod].real[:size])\n",
    "        imag = np.array(data[mod].imag[:size])\n",
    "        signal = np.concatenate([real, imag], axis=1)\n",
    "        features.append(signal)\n",
    "        labels.append(mods.index(mod) * np.ones([size, 1]))\n",
    "\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = import_from_mat(data,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = features.astype(np.float32)\n",
    "labels = labels.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = features\n",
    "y = labels.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Define the model\"\"\"\n",
    "\n",
    "    def __init__(self, dr):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(2, 256, 3, padding=1),  # batch, 256, 1024\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(256, 80, 3, padding=1),  # batch, 80, 1024\n",
    "            nn.BatchNorm1d(80),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d()\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(80 * 1024, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dr)\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, class_num),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, **kwargs):\n",
    "        x = x.reshape((x.size(0), 2, -1))\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Classifier and Callback. \n",
    "The Callbacks are used to calculate score and print train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import Callback, EpochScoring, Checkpoint, EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skorch.utils import data_from_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Score_ConfusionMatrix(EpochScoring):\n",
    "    def on_epoch_end(self, net, dataset_train, dataset_valid, **kwargs):\n",
    "        \n",
    "        EpochScoring.on_epoch_end(self, net, dataset_train, dataset_valid)\n",
    "        \n",
    "        X_test, y_test = data_from_dataset(dataset_valid)\n",
    "        y_pred = net.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        history = net.history\n",
    "        history.record(\"confusion_matrix\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Print_Score_CM(Callback):\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        self.batch_num = 0\n",
    "        self.sample_num = 0\n",
    "        self.size = size\n",
    "        \n",
    "    def on_batch_end(self, net, **kwargs):\n",
    "        self.batch_num += 1\n",
    "        self.sample_num += kwargs['X'].shape[0]\n",
    "        if self.batch_num % 1 == 0:\n",
    "            percent = self.sample_num/self.size\n",
    "            history = net.history\n",
    "            training = kwargs[\"training\"]\n",
    "            if training:\n",
    "                print('processed: {0:.4f}, ' \n",
    "                      'train_batch: {1}, '\n",
    "                      'train_loss:{2:.4f}'.format(\n",
    "                          percent,\n",
    "                          history[-1, \"batches\", -1, \"train_batch_size\"],\n",
    "                          history[-1, \"batches\", -1, \"train_loss\"]\n",
    "                      ))\n",
    "            else:\n",
    "                print('processed: {0:.4f}, ' \n",
    "                      'valid_batch: {1}, '\n",
    "                      'valid_loss:{2:.4f}'.format(\n",
    "                          percent,\n",
    "                          history[-1, \"batches\", -1, \"valid_batch_size\"],\n",
    "                          history[-1, \"batches\", -1, \"valid_loss\"]\n",
    "                      ))\n",
    "    def on_epoch_end(self, net, **kwargs):\n",
    "        self.batch_num = 0\n",
    "        self.sample_num = 0\n",
    "        history = net.history\n",
    "        result = history[-1].copy()\n",
    "        result.pop(\"confusion_matrix\")\n",
    "        result.pop(\"batches\")\n",
    "        print(\"epoch: {0}, \"\n",
    "              \"dur: {1:.2f}s, \"\n",
    "              \"val_acc: {2:.4f}{3}, \"\n",
    "              \"val_loss: {4:.4f}{5}, \"\n",
    "              \"saved: {6}\".format(\n",
    "                  history[-1, \"epoch\"],\n",
    "                  history[-1, \"dur\"],\n",
    "                  history[-1, \"accuracy\"],\n",
    "                  \"(best)\" if history[-1, \"accuracy_best\"] else \"\",\n",
    "                  history[-1, \"valid_loss\"],\n",
    "                  \"(best)\" if history[-1, \"valid_loss_best\"] else \"\",\n",
    "                  history[-1, \"event_cp\"]\n",
    "              ))\n",
    "        print(\"Confusion matrix:\\n {0}\".format(\n",
    "            history[-1, \"confusion_matrix\"]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cp = Checkpoint(dirname='best')\n",
    "early_stop = EarlyStopping(patience=20)\n",
    "net = NeuralNetClassifier(\n",
    "    Discriminator,\n",
    "    max_epochs=200,\n",
    "    lr=0.01,\n",
    "    module__dr=0.6,\n",
    "    device='cuda',\n",
    "    callbacks=[('best',cp),\n",
    "               ('early', early_stop)\n",
    "              ],\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_valid__shuffle=False\n",
    ")\n",
    "\n",
    "# score = Score_ConfusionMatrix(scoring=\"accuracy\", lower_is_better=False)\n",
    "# pt = Print_Score_CM(X.shape[0])\n",
    "\n",
    "# net.set_params(callbacks__valid_acc=score)\n",
    "# net.set_params(callbacks__print_log=pt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ------------  -----------  ------------  ----  --------\n",
      "      1        0.3432       0.8901        0.2117     +  320.2734\n",
      "      2        0.1563       0.9635        0.1007     +  318.2180\n",
      "      3        0.1161       0.9695        0.0824     +  318.1572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=Discriminator(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1d(2, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1d(256, 80, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (fc1): Sequential(\n",
       "      (0): Linear(in_features=81920, out_features=256, bias=True)\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.6)\n",
       "    )\n",
       "    (fc2): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=11, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = net.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30076     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0 28374     0     0     1     0     0  1279     0     0   630]\n",
      " [    0     0 29880     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0 29946     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0 29835     0     0     2     0     0   100]\n",
      " [    0     0     0     0     0 29872     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0 29998     0     0     0     0]\n",
      " [    0  1692     0     0    13     0     0 24179     0     0  4307]\n",
      " [    0     0     0     0     0     0     0     0 29800     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0 29949     0]\n",
      " [    0   185     0     0    39     0     0   560     0     0 29283]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch (choose parameter to try, lr, warm_start_param（yes or not, parameters）, LRScheduler, dropout, max_epoch=200, patenice=20 )\n",
    "对数尺度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'lr': [0.0005, 0.001, 0.005, 0.01, 0.05],\n",
    "    'module__dr': norm(loc=0.5, scale=0.1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    net,\n",
    "    scoring='accuracy',\n",
    "    param_distributions =param_dist,\n",
    "    n_iter=20,\n",
    "    cv = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_search.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
